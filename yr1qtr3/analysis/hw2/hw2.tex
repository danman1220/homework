%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fontsize=11pt]{scrartcl} % 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{mathrsfs}

\usepackage[margin=1in]{geometry}

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}

\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}

\newtheorem{lemma}{Lemma}
%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{Analysis} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Homework 2 \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Daniel Halmrast} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

% Problems
\section*{Problem 1}
Characterize all the norm-closed faces of the unit ball in $C([0,1])$ under the
sup norm.
\\
\\
\begin{proof}
    I assert that the norm-closed faces of the unit ball in $C([0,1])$ have the
    following form: Let $V$ be a disjoint union of open subintervals of $[0,1]$,
    and for each closed subinterval in $V^c$ assign it to the set $N$ or $P$.
    Then, a face can be defined as
    \[
        F = \{f\in B\ |\ f(N) = \{-1\}, f(P)=\{1\}\}
    \]
    where $B$ is the unit ball in $C([0,1])$. Note that if $V=[0,1]$, we recover
    $B$. So, assume from here on out that either $N$ or $P$ (or both) is
    nonempty.

    First, we prove that sets of this form are faces. To do so, we must prove
    that $F$ is convex, and that $F$ is ``closed under linear interpolation''.

    We first show that $F$ is convex. Let $f,g\in F$, and consider the function
    \[
        h(x) = \lambda f(x) + (1-\lambda)g(x)
    \]
    for $\lambda\in[0,1]$,
    which is a linear combination of continuous functions, and is therefore
    continuous. Furthermore,
    \[
        \sup_x |h(x)|\leq \lambda \sup_x|f(x)| + (1-\lambda)\sup_x|g(x)|
        \leq 1
    \]
    and so $h\in B$. Furthermore, for $x\in N$,
    \[
        h(x) = \lambda f(x) + (1-\lambda)g(x) = \lambda(-1) + (1-\lambda)(-1)=-1
    \]
    and similarly for $x\in P$,
    \[
        h(x) = 1
    \]
    Thus, $h\in F$ as desired.

    Next, we show that for $h\in F$, $f,g\in B$ and $t\in (0,1)$ with
    \[
        h(x) = tf(x) + (1-t)g(x)
    \]
    then $f(x)$ and $g(x)$ are in $F$ as well.

    This follows immediately, since for $x\in N$,
    \[
        h(x) = -1 = tf(x) + (1-t)g(x)
    \]
    and $f(x),g(x)\in [-1,1]$, which forces $f(x) = g(x) = -1$. Similarly, for
    $x\in P$, $f(x)=g(x)=1$. Thus, $f,g\in F$ as desired.

    Thus, we have shown that $F$ is a face of $B$. Next, we wish to show that
    all norm-closed faces of $B$ have this form.


    So, let $F$ be an arbitrary norm-closed face of $B$. Define 
    \[
        N = \bigcap_{f\in F}f^{-1}(\{-1\})
    \]
    and
    \[
        P = \bigcap_{f\in F}f^{-1}(\{1\})
    \]
    That is, for all $f\in F$, $f(P) = \{1\}$ and $f(N) = \{-1\}$. I assert that
    $F$ is equal to the set
    \[
        \tilde{F} = \{f\in B\ |\ f(N)=\{-1\}, f(P)=\{1\}\}
    \]

    Clearly, $F\subset \tilde{F}$ by definition of $N$ and $P$. So, all we need
    to show is that $\tilde{F}\subset F$.

    So, let $g\in\tilde{F}$ be an arbitrary function. We wish to uniformly
    approximate $g$ with things in $F$, and then use the fact that $F$ is
    norm-closed to show that $g$ is in $F$. Note first that $g$ is guaranteed to
    match with any function in $F$ on $N$ and $P$ by construction, so we only
    have to approximate $g$ on $V= (P\cup N)^c$.

    Now, for each $y\in V$, by definition there is a function $f_y\in F$ with
    $f_y(U)\in (-1,1)$ for $U$ a neighborhood of $y$. In particular, we can use
    the fact that $F$ is a face (and closed under linear interpolations) to
    construct a $\tilde{f}_y$ such that $\tilde{f}_y(y) = g(y)$. In fact, for
    fixed $\varepsilon>0$, we can find neighborhoods $U_y$ for which
    $\tilde{f}_y|_{U_y}$ is within $\varepsilon$ of $g|_{U_y}$ in supremum.
    Taking all such $U_y$ across $[0,1]$ (where trivially $f(y)=g(y)$ for $y\in
    N\cup P$) we get an open cover of $[0,1]$, which has a finite subcover
    $\{U_{y_i}\}$.

    For each $\tilde{f}_{y_i}$, change it via linear interpolation on
    $V\setminus U_{y_i}$ to be within $\varepsilon$ of zero.

    Finally, stitch together the finite altered $\tilde{f}_{y_i}$ to obtain a
    function $\tilde{f}\in F$ that approximates $g$ within $\varepsilon$ in sup norm.
    Taking limits of such $\tilde{f}$ yields $g$, and so $g\in F$ as desired.

\end{proof}

\newpage

\section*{Problem 2}
Characterize all the extreme points of the set
\[
    K = \{ f\in \ell^1\ |\ 0\leq f(n)\leq 1\forall n\in \N, \int_{\N}fd\mu = 1\}
\]

\begin{proof}
    I assert that all the extreme points of $K$ are the basis vectors $e_n =
    (0,\dots,0,1,0,\dots)$ where $1$ is in the $n$th position.
    
    First, we observe that these points are indeed extreme points. Suppose that
    $f,g\in K$ with
    \[
        e_n = tf + (1-t)g
    \]
    for some $t\in (0,1)$. Now, for all $i\neq n$, we have
    \[
        0 = tf(i) + (1-t)g(i)
    \]
    but $f(i)$ and $g(i)$ are both in $[0,1]$, and $t$ and $1-t$ are both
    positive and nonzero, which forces $f(i)=g(i)=0$. The normalization
    condition on $K$ forces $\int_{\N}fd\mu = \int_{\N}gd\mu = 1$ which implies
    that $f(n)=g(n) = 1$, and so $f=g=e_n$. Thus, each $e_n$ is indeed an
    extreme point of $K$.

    Next, we observe that these are all the extreme points. Suppose $f$ is not
    $e_n$ for any $n$. In particular, this means that there are at least two
    integers $n_01,n_2$ for which $f(n_1)\in (0,1)$ and $f(n_2)\in (0,1)$. Now,
    let $\varepsilon>0$ be such that $f(n_i)\pm\varepsilon\in (0,1)$.

    Now, define $g$ and $h$ as
    \[
\begin{aligned}
    g(i) &=
\begin{cases}
    f(n_1) + \varepsilon, &i=n_1\\
    f(n_2) - \varepsilon, &i=n_2\\
    f(i), &\text{else}
\end{cases}\\
    h(i) &=
\begin{cases}
    f(n_1) - \varepsilon, &i=n_1\\
    f(n_2) + \varepsilon, &i=n_2\\
    f(i), &\text{else}
\end{cases}
\end{aligned}
    \]
    By our choice of $\varepsilon$, $g(\N),h(\N)\in [0,1]$ and by construction
    \[
        \int_{\N}gd\mu = \int_{\N}hd\mu = 1
    \]
    since we have only moved $\varepsilon$ from one element of the sum to
another. Thus, $g,h\in K$. Furthermore, for all $i\in \N$, $i\neq n_1,n_2$,
    \[
        \frac{1}{2}g(i) +\frac{1}{2}h(i) = \frac{1}{2}f(i)+\frac{1}{2}f(i) =
        f(i)
    \]
    and
    \[
        \begin{aligned}
            \frac{1}{2}g(n_1) + \frac{1}{2}h(n_1) &=
            \frac{1}{2}(f(n_1)+\varepsilon) + \frac{1}{2}(f(n_1)-\varepsilon)\\
            &= \frac{1}{2}(2f(n_1)) = f(n_1)
    \end{aligned}
    \]
    and
    \[
        \begin{aligned}
            \frac{1}{2}g(n_2) + \frac{1}{2}h(n_2) &=
            \frac{1}{2}(f(n_2)-\varepsilon) + \frac{1}{2}(f(n_2)+\varepsilon)\\
            &= \frac{1}{2}(2f(n_2)) = f(n_2)
    \end{aligned}
    \]
    which verifies that $f = \frac{1}{2}g + \frac{1}{2}h$, and thus $g$ and $h$
    belong to the same face as $f$, and in particular, $f$ is not an extreme
    point.
\end{proof}

\newpage
\section*{Problem 3}
Prove or disprove the following:
\subsection*{Part A}
$L^1(X,\mathbb{M},\mu)$ is an algebra under pointwise multiplication over $\C$,
where $(X,\mathbb{M},\mu)$ is a measure space.
\\
\\
\begin{proof}
    This is not true in general. Take $L^1([0,1],\lambda^1)$, and let $f(x) =
    g(x) = \frac{1}{\sqrt{x}}$. We know that
    \[
        \int_{[0,1]}\frac{1}{\sqrt{x}}d\lambda^1(x) = 2
    \]
    and so $f,g\in L^1([0,1],\lambda^1)$. However, their pointwise product is
    \[
        f(x)g(x) = \frac{1}{x}
    \]
    with
    \[
        \int_{[0,1]}|f(x)g(x)|d\lambda^1(x) =
        \int_{[0,1]}\frac{1}{x}d\lambda^1(x) = \infty
    \]
    and so $f(x)g(x)$ is not in $L^1([0,1],\lambda^1)$ and thus
    $L^1([0,1],\lambda^1)$ is not closed under products, and is not an algebra.
\end{proof}

\subsection*{Part B}
Same question for the subspace of bounded functions in $L^1(X,\mathbb{M},\mu)$.
\\
\\
\begin{proof}
    Let $V$ be the subspace of bounded functions in $L^1(X,\mathbb{M},\mu)$. I
    assert that this is an algebra. First, we observe that this subspace is
    indeed a subspace of $L^1(X,\mathbb{M},\mu)$, and is thus closed under
    addition and scalar multiplication. Thus, to prove it is an algebra, we just
    need to show it is closed under products.

    So, let $f,g\in V$. We first show $f(x)g(x)$ is in $L^1(X,\mathbb{M},\mu)$,
    then we show it is bounded.

    To see that $f(x)g(x)\in L^1(X,\mathbb{M},\mu)$, we use Holder's inequality
    to assert that
    \[
        \|fg\|_1 \leq \|f\|_1\|g\|_{\infty} < \infty
    \]
    since $\|f\|_1<\infty$ and $\|g\|_{\infty}<\infty$. Thus, $fg\in
    L^1(X,\mathbb{M},\mu)$.

    Finally, we observe that $fg$ is bounded, since both $f$ and $g$ are
    individually bounded. In particular, we know that (denoting the bound on $f$
    as $\|f\|_B$)
    \[
        \|fg\|_B \leq \|f\|_B\|g\|_B
    \]
    since
    \[
        |f(x)g(x)| \leq |\|f\|_Bg(x)|\leq \|f\|_B\|g\|_B
    \]
    for each $x$. Thus, $\|f\|_B\|g\|_B$ is an upper bound on $fg$ as desired.
\end{proof}


\newpage
\section*{Problem 4}
Prove that the set $M_1^+$ of all positive self-adjoint $n\times n$ complex
matrices between $0$ and $1$ is convex, and its extreme points are the
projections.
\\
\\
\begin{proof}
    We first show this set is convex. To do so, let $A,B\in M_1^+$ and consider
    \[
        C = \lambda A + (1-\lambda)B
    \]
    for $\lambda\in [0,1]$. First, observe that $C$ is self-adjoint, since
    \[
        C^* = \lambda A^* + (1-\lambda)B^* = \lambda A + (1-\lambda)B = C
    \]
    Furthermore, $C$ is positive, since
    \[
        \begin{aligned}
        \langle C\eta,\eta\rangle &= \lambda\langle A\eta,\eta\rangle +
        (1-\lambda)\langle B\eta,\eta\rangle\\
        &\geq 0
    \end{aligned}
    \]
    since both $A$ and $B$ are positive, and $\lambda, (1-\lambda)\geq0$.

    Finally, we note that $C\leq 1$, since 
    \[
\begin{aligned}
    \langle (I-C)\eta,\eta\rangle &= \langle (I - (\lambda A +
    (1-\lambda)B))\eta,\eta\rangle\\
    &= \langle ((\lambda + (1-\lambda))I - (\lambda A +
    (1-\lambda)B))\eta,\eta\rangle\\
    &= \lambda \langle (I-A)\eta,\eta\rangle + (1-\lambda)\langle
    (I-B)\eta,\eta\rangle\\
    &\geq 0
\end{aligned}
    \]
    Where we used the fact that $A,B\leq 1$, and so $I-A$ and $I-B$ are
    positive.

    Next, we assert that the projections are the extreme points. We begin by
    asserting that for any $M\in M_1^+$, $\sigma(M)\subset [0,1]$. To see this,
    note that $M$ being self-adjoint implies that $\sigma(M)$ is real, and since
    $M$ is positive, $\sigma(M)$ must be positive as well (if this were not the
        case, then there is some vector $v$ for which $Mv = \lambda v$ with
        $\lambda<0$, and $\langle Mv,v\rangle = \lambda\|v\|^2<0$ a
    contradiction).
    Of course, since $M\leq 1$, this implies that $\sigma(M)\leq 1$ as well (if
        this were not the case, then there is some vector $v$ with $Mv=\lambda
        v$ and $\lambda>1$, but then $\langle (I-M)v,v\rangle = \|v\|^2 -
    \lambda\|v\|^2<0$, a contradiction).

    Thus, $\sigma(M)\subset [0,1]$ as desired.

    So, suppose $P$ is a projection operator, and $A,B\in M_1^+$, $t\in (0,1)$
    with $P=tA+(1-t)B$. Suppose $v$ is such that $Pv=v$ and $\|v\|=1$. Then, we
    have that
    \[
        \langle Pv,v\rangle = 1 = t\langle Av,v\rangle + (1-t)\langle
        Bv,v\rangle
    \]
    Now, since $\langle Av,v\rangle$ and $\langle Bv,v\rangle$ are less than or
    equal to $1$ (since $A,B\leq 1$), they must be equal to $1$ to satisfy the
    above equation. However, the only way that $\langle Av,v\rangle=1$ is if
    $Av=v$. This follows from basic linear algebra: decompose $Av$ into a
    component parallel to $v$ denoted $\lambda_1v$ and a component orthogonal to
    $v$ denoted $\lambda_2v_c$. That is,
    \[
        Av = \lambda_1v+\lambda_2v_c
    \]
    with $\lambda_1^2 + \lambda_2^2 = \|Av\|\leq 1$. But then
    \[
        \langle Av,v\rangle = 1 = \lambda_1\langle v,v\rangle + \lambda_2\langle
        v_c,v\rangle = \lambda_1
    \]
    Thus, $\lambda_1=1$ and $\lambda_2=0$, and so $Av=v$. Similarly, $Bv=v$.
    This argument applies to all $v$ for which $Pv=v$.

    Applying the same argument to $I-P = t(I-A) +(1-t)(I-B)$ we see that if
    $Pv=0$, then $Av=Bv=0$ as well. Thus, writing a generic vector $x$ as
    $x= Px + (I-P)x$, we have
    \[
        \begin{aligned}
            Ax &= A(Px + (I-P)x)\\
            &= Px
    \end{aligned}
    \]
    and similarly for $B$. Thus, $P$ is an extreme point, as desired.

    Finally, we show that these are the only extreme points. To see this, let
    $M\in M_1^+$ be a matrix that is not a projection. That is, $M$ has at least
    one eigenvalue in $(0,1)$. 

    So, let
    \[
        M = \sum_{i=1}^n \lambda_i|e_j\ra\la e_j|
    \]
    be its spectral decomposition, and let $\lambda_1\in(0,1)$. In particular,
    let $\varepsilon>0$ such that $\lambda_1\pm \varepsilon\in (0,1)$. Then,
    define 
    \[
        A = (\lambda_1+\varepsilon)|e_1\ra\la e_1| +
    \sum_{i=2}^n\lambda_i|e_i\ra\la e_i|
    \]
    and
    \[
        B = (\lambda_1-\varepsilon)|e_1\ra\la e_1| +
    \sum_{i=2}^n\lambda_i|e_i\ra\la e_i|
    \]
    which are easily verified to be in $M_1^+$. Then,
    \[
        \frac{1}{2}A + \frac{1}{2}B = M
    \]
    and thus $M$ cannot be an extreme point.
\end{proof}

\end{document}
